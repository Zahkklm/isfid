{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# calculate inception score for cifar-10 in Keras\n",
        "from math import floor\n",
        "from numpy import ones\n",
        "from numpy import expand_dims\n",
        "from numpy import log\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import exp\n",
        "from numpy.random import shuffle\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "#from keras.datasets import cifar10\n",
        "from skimage.transform import resize\n",
        "from numpy import asarray\n",
        "\n",
        "# scale an array of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        "  images_list = list()\n",
        "  for image in images:\n",
        "    # resize with nearest neighbor interpolation\n",
        "    new_image = resize(image, new_shape, 0)\n",
        "    # store\n",
        "    images_list.append(new_image)\n",
        "  return asarray(images_list)\n",
        "\n",
        "# assumes images have any shape and pixels in [0,255]\n",
        "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
        " # load inception v3 model\n",
        " model = InceptionV3()\n",
        " # enumerate splits of images/predictions\n",
        " scores = list()\n",
        " n_part = floor(images.shape[0] / n_split)\n",
        " for i in range(n_split):\n",
        "   # retrieve images\n",
        "  ix_start, ix_end = i * n_part, (i+1) * n_part\n",
        "  subset = images[ix_start:ix_end]\n",
        " # convert from uint8 to float32\n",
        " subset = subset.astype('float32')\n",
        " # scale images to the required size\n",
        " subset = scale_images(subset, (299,299,3))\n",
        " # pre-process images, scale to [-1,1]\n",
        " subset = preprocess_input(subset)\n",
        " # predict p(y|x)\n",
        " p_yx = model.predict(subset)\n",
        " # calculate p(y)\n",
        " p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
        " # calculate KL divergence using log probabilities\n",
        " kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
        " # sum over classes\n",
        " sum_kl_d = kl_d.sum(axis=1)\n",
        " # average over images\n",
        " avg_kl_d = mean(sum_kl_d)\n",
        " # undo the log\n",
        " is_score = exp(avg_kl_d)\n",
        " # store\n",
        " scores.append(is_score)\n",
        " # average across images\n",
        " is_avg, is_std = mean(scores), std(scores)\n",
        " return is_avg, is_std\n",
        "\n",
        "(images, _), (_, _) = #bu kısıma test görüntü dataseti eklenmeli (dataset tercihen insan yüzlerinin bulunduğu geniş kapsamlı image classification dataseti olmalıdır)\n",
        "# shuffle images\n",
        "shuffle(images)\n",
        "print('loaded', images.shape)\n",
        "# calculate inception score\n",
        "is_avg, is_std = calculate_inception_score(images)\n",
        "print('score', is_avg, is_std)"
      ],
      "metadata": {
        "id": "aMErdsPZPd4f"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}